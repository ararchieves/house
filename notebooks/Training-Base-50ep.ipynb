{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Download and setup project and data","metadata":{"execution":{"iopub.status.busy":"2023-09-07T09:09:35.103714Z","iopub.execute_input":"2023-09-07T09:09:35.104088Z","iopub.status.idle":"2023-09-07T09:09:35.109109Z","shell.execute_reply.started":"2023-09-07T09:09:35.104057Z","shell.execute_reply":"2023-09-07T09:09:35.107935Z"}}},{"cell_type":"code","source":"!pip -q install openai-clip\n!pip -q install gdown","metadata":{"execution":{"iopub.status.busy":"2023-09-12T09:04:27.970631Z","iopub.execute_input":"2023-09-12T09:04:27.970994Z","iopub.status.idle":"2023-09-12T09:04:54.713051Z","shell.execute_reply.started":"2023-09-12T09:04:27.970966Z","shell.execute_reply":"2023-09-12T09:04:54.711723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone 'https://github.com/ararchieves/house.git'\n%cd house","metadata":{"execution":{"iopub.status.busy":"2023-09-12T09:04:54.715842Z","iopub.execute_input":"2023-09-12T09:04:54.716254Z","iopub.status.idle":"2023-09-12T09:04:56.906884Z","shell.execute_reply.started":"2023-09-12T09:04:54.716201Z","shell.execute_reply":"2023-09-12T09:04:56.905142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gdown\ndata_link = 'https://drive.google.com/file/d/1-zD25r3PPt4fDJBPKbFy6Qdemeo039lG/view?usp=sharing' \ngdown.download(url=data_link, output='data_cat.zip', quiet=False, fuzzy=True)\n\nprint(\"Unzipping data\")\n!unzip -q 'data_cat' -d '.'\n!mv 'data_cat' 'data'\n!rm 'data_cat.zip'\nprint(\"Data Unzipping Complete!\")","metadata":{"execution":{"iopub.status.busy":"2023-09-12T09:04:56.908952Z","iopub.execute_input":"2023-09-12T09:04:56.909379Z","iopub.status.idle":"2023-09-12T09:06:01.287389Z","shell.execute_reply.started":"2023-09-12T09:04:56.909337Z","shell.execute_reply":"2023-09-12T09:06:01.285823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Code","metadata":{}},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import os\nimport yaml\nimport random\n\nfrom models.clipseg import CLIPDensePredT\n\nimport torch\nimport torchvision\nfrom torch import nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision.io import read_image, ImageReadMode\n\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-09-12T09:14:24.432033Z","iopub.execute_input":"2023-09-12T09:14:24.432462Z","iopub.status.idle":"2023-09-12T09:14:24.439546Z","shell.execute_reply.started":"2023-09-12T09:14:24.432431Z","shell.execute_reply":"2023-09-12T09:14:24.438446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Config Variables","metadata":{"execution":{"iopub.status.busy":"2023-09-07T09:15:01.661748Z","iopub.execute_input":"2023-09-07T09:15:01.662118Z","iopub.status.idle":"2023-09-07T09:15:01.666991Z","shell.execute_reply.started":"2023-09-07T09:15:01.662088Z","shell.execute_reply":"2023-09-07T09:15:01.665831Z"}}},{"cell_type":"code","source":"# Data\nROOT_DIR = './data'\nBATCH_SIZE = 12\nTRANSFORMS = None\nSHUFFLE = True\nSEED = 42\nNUM_WORKERS = 2\nPIN_MEMORY = True\n# Training\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nLEARNING_RATE = 1e-3\nEPOCHS = 50\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T09:18:05.558018Z","iopub.execute_input":"2023-09-12T09:18:05.558840Z","iopub.status.idle":"2023-09-12T09:18:05.565964Z","shell.execute_reply.started":"2023-09-12T09:18:05.558794Z","shell.execute_reply":"2023-09-12T09:18:05.564961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Loading and Visualization","metadata":{}},{"cell_type":"code","source":"class ChineseCityDataset(Dataset):\n    def __init__(self, root_dir='./data', split='train', transform=None):\n        super().__init__()\n\n        if split == 'train':\n            self.base_dir = f'{root_dir}/train'\n        elif split == 'test':\n            self.base_dir = f'{root_dir}/test'\n        elif split == 'val':\n            self.base_dir = f'{root_dir}/val'\n        else:\n            raise Exception(f\"Invalid split parameter! '{split}' not in ['train', 'test', 'val']\")\n\n        # variables\n        self.image_dir = f'{self.base_dir}/images'\n        self.masks_dir = f'{self.base_dir}/masks'\n\n        self.images = os.listdir(self.image_dir)\n        self.mask_dirs = os.listdir(self.masks_dir)\n\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image_name = self.images[idx]\n\n        img = read_image(f'{self.base_dir}/images/{image_name}', mode=ImageReadMode.RGB) / 255\n\n        # Remove the view id from the image name: Image Name = {image_id}_{view}\n        masks_dir_id = image_name.split('_')[0]\n\n        # Masks info\n        ## 0 = Ground Floor: 0\n        ## 1-4 =  Short Building or a house: 1\n        ## 5-10 = Meduim Building: 2\n        ## 11+ = Tall Building: 3\n\n        masks = []\n        for mask_number in range(4):\n            mask = read_image(f'{self.masks_dir}/{masks_dir_id}/{mask_number}.png', mode=ImageReadMode.GRAY) / 255\n            masks.append(mask)\n\n\n        if self.transform:\n            img = self.transform(img)\n            masks = [self.transform(mask) for mask in masks]\n\n        return img, masks","metadata":{"execution":{"iopub.status.busy":"2023-09-12T09:18:05.568815Z","iopub.execute_input":"2023-09-12T09:18:05.569372Z","iopub.status.idle":"2023-09-12T09:18:05.581905Z","shell.execute_reply.started":"2023-09-12T09:18:05.569335Z","shell.execute_reply":"2023-09-12T09:18:05.580802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = ChineseCityDataset(root_dir=ROOT_DIR, split='train')\ntrainloader = DataLoader(train_data,\n                         batch_size=BATCH_SIZE,\n                         shuffle=SHUFFLE,\n                         generator=torch.Generator().manual_seed(SEED),\n                         num_workers=NUM_WORKERS,\n                         pin_memory=PIN_MEMORY\n                         )\nprint(f\"Length of trainloader is: {len(trainloader)}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-12T09:18:05.583731Z","iopub.execute_input":"2023-09-12T09:18:05.584167Z","iopub.status.idle":"2023-09-12T09:18:05.605462Z","shell.execute_reply.started":"2023-09-12T09:18:05.584132Z","shell.execute_reply":"2023-09-12T09:18:05.604575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_data = ChineseCityDataset(root_dir=ROOT_DIR, split='val')\nvalloader = DataLoader(val_data,\n                         batch_size=BATCH_SIZE,\n                         shuffle=SHUFFLE,\n                         generator=torch.Generator().manual_seed(SEED),\n                         num_workers=NUM_WORKERS,\n                         pin_memory=PIN_MEMORY\n                         )\nprint(f\"Length of valloader is: {len(valloader)}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-12T09:18:05.606761Z","iopub.execute_input":"2023-09-12T09:18:05.607677Z","iopub.status.idle":"2023-09-12T09:18:05.615468Z","shell.execute_reply.started":"2023-09-12T09:18:05.607645Z","shell.execute_reply":"2023-09-12T09:18:05.614514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, [mask0, mask1, mask2, mask3] = next(iter(trainloader))","metadata":{"execution":{"iopub.status.busy":"2023-09-12T09:18:05.618483Z","iopub.execute_input":"2023-09-12T09:18:05.619279Z","iopub.status.idle":"2023-09-12T09:18:07.311924Z","shell.execute_reply.started":"2023-09-12T09:18:05.619223Z","shell.execute_reply":"2023-09-12T09:18:07.310656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(5, 5, figsize=(20, 20))\n\naxes[0,0].set_title(\"View\")\naxes[0,1].set_title(\"Ground Floor\")\naxes[0,2].set_title(\"Short Buildings\")\naxes[0,3].set_title(\"Mudium Buildings\")\naxes[0,4].set_title(\"Tall Buildings\")\n\nfor idx in range(5):\n    axes[idx, 0].imshow(images[idx].permute(1,2,0))\n    axes[idx, 1].imshow(mask0[idx].permute(1,2,0))\n    axes[idx, 2].imshow(mask1[idx].permute(1,2,0))\n    axes[idx, 3].imshow(mask2[idx].permute(1,2,0))\n    axes[idx, 4].imshow(mask3[idx].permute(1,2,0))\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T09:18:07.316069Z","iopub.execute_input":"2023-09-12T09:18:07.316425Z","iopub.status.idle":"2023-09-12T09:18:11.553015Z","shell.execute_reply.started":"2023-09-12T09:18:07.316397Z","shell.execute_reply":"2023-09-12T09:18:11.552155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Setup ","metadata":{}},{"cell_type":"code","source":"model = CLIPDensePredT(version='ViT-B/16', complex_trans_conv=True).to(DEVICE)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T09:18:11.554747Z","iopub.execute_input":"2023-09-12T09:18:11.555384Z","iopub.status.idle":"2023-09-12T09:18:16.022872Z","shell.execute_reply.started":"2023-09-12T09:18:11.555350Z","shell.execute_reply":"2023-09-12T09:18:16.021804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"Total number of trainable parameters are: {trainable_params:,}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-12T09:18:16.024541Z","iopub.execute_input":"2023-09-12T09:18:16.024940Z","iopub.status.idle":"2023-09-12T09:18:16.032866Z","shell.execute_reply.started":"2023-09-12T09:18:16.024904Z","shell.execute_reply":"2023-09-12T09:18:16.031717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RMSELoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.mse = nn.MSELoss()\n        \n    def forward(self, ture, pred):\n        return torch.sqrt(self.mse(ture, pred))","metadata":{"execution":{"iopub.status.busy":"2023-09-12T09:18:16.034517Z","iopub.execute_input":"2023-09-12T09:18:16.034864Z","iopub.status.idle":"2023-09-12T09:18:16.043716Z","shell.execute_reply.started":"2023-09-12T09:18:16.034833Z","shell.execute_reply":"2023-09-12T09:18:16.042605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\ncriterion = RMSELoss()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T09:18:16.046268Z","iopub.execute_input":"2023-09-12T09:18:16.047286Z","iopub.status.idle":"2023-09-12T09:18:16.057208Z","shell.execute_reply.started":"2023-09-12T09:18:16.047252Z","shell.execute_reply":"2023-09-12T09:18:16.056212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(f'config/prompts.yaml', 'r') as f:\n    _prompts = yaml.safe_load(f)\n\n\ndef get_random_prompts(mask_type, n_prompts, prompts=_prompts):\n    valid_mask_types = [0,1,2,3]\n    assert mask_type in valid_mask_types, f\"Invalid mask_type! {mask_type} not in {valid_mask_types}\"\n\n    key_list = [\"PromptsMask0\", \"PromptsMask1\", \"PromptsMask2\", \"PromptsMask3\"]\n\n    random_prompts = []\n    for i in range(n_prompts):\n        random_prompt = random.choice(prompts[key_list[mask_type]])\n        random_prompts.append(random_prompt)\n\n    return random_prompts\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T09:18:16.058677Z","iopub.execute_input":"2023-09-12T09:18:16.059045Z","iopub.status.idle":"2023-09-12T09:18:16.075708Z","shell.execute_reply.started":"2023-09-12T09:18:16.058990Z","shell.execute_reply":"2023-09-12T09:18:16.074812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss_list = []\nval_loss_list = []\n\n\nfor epoch in range(EPOCHS):\n    epoch_train_loss = 0.0\n    # Training\n    model.train()\n    for idx, (images, masks) in tqdm(enumerate(trainloader), total=len(trainloader), desc=f'Training - Epoch {epoch+1}/{EPOCHS}: '):\n        images = images.to(DEVICE, non_blocking=True)\n        masks = [mask.to(DEVICE, non_blocking=True) for mask in masks]\n\n        # Prepare the images and masks for forward pass\n        \n        _images = images.repeat(4, 1, 1, 1)\n        _masks = torch.cat(masks, dim=0)\n        prompts = []\n        for i in range(4):\n            prompts += get_random_prompts(i, images.shape[0])\n\n        optimizer.zero_grad()\n\n        pred_mask = model(_images, prompts)[0]\n        loss = criterion(pred_mask, _masks)\n\n        loss.backward()\n        optimizer.step()\n        \n        epoch_train_loss += loss.item()\n    train_loss_list.append(epoch_train_loss)\n    \n    # Validation \n    epoch_val_loss = 0.0\n    model.eval()\n    with torch.no_grad():\n        for idx, (images, masks) in tqdm(enumerate(valloader), total=len(valloader), desc=f'Validation - Epoch {epoch+1}/{EPOCHS}: '):\n            images = images.to(DEVICE, non_blocking=True)\n            masks = [mask.to(DEVICE, non_blocking=True) for mask in masks]\n\n            _images = images.repeat(4, 1, 1, 1)\n            _masks = torch.cat(masks, dim=0)\n            prompts = []\n            for i in range(4):\n                prompts += get_random_prompts(i, images.shape[0])\n                \n            pred_mask = model(_images, prompts)[0]\n            loss = criterion(pred_mask, _masks)\n            \n            epoch_val_loss += loss.item()\n        val_loss_list.append(epoch_train_loss)\n    \n    print(f\"Trianing Loss: {epoch_train_loss:.4f} - Validation Loss: {epoch_val_loss:.4f}\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-09-12T09:18:16.077310Z","iopub.execute_input":"2023-09-12T09:18:16.078023Z","iopub.status.idle":"2023-09-12T09:18:23.780594Z","shell.execute_reply.started":"2023-09-12T09:18:16.077991Z","shell.execute_reply":"2023-09-12T09:18:23.778718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"min_y = min(min(train_loss_list), min(val_loss_list))\nmax_y = max(max(train_loss_list), max(val_loss_list))\nplt.plot(train_loss_list, label='Training Loss', color='r')\nplt.plot(val_loss_list, label='Validation Loss', color='b')\nplt.ylim(min_y, max_y)\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T09:18:23.782015Z","iopub.status.idle":"2023-09-12T09:18:23.783206Z","shell.execute_reply.started":"2023-09-12T09:18:23.782910Z","shell.execute_reply":"2023-09-12T09:18:23.782935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"trained_model.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-09-12T09:18:23.784799Z","iopub.status.idle":"2023-09-12T09:18:23.785626Z","shell.execute_reply.started":"2023-09-12T09:18:23.785364Z","shell.execute_reply":"2023-09-12T09:18:23.785387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}